{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous kernel - https://www.kaggle.com/priteshshrivastava/ieee-pipeline-1-create-validation-set\n",
    "\n",
    "Input - Train & val, test CSVs\n",
    "\n",
    "Output - Val & Test preds\n",
    "\n",
    "Next kernel - Meta model https://www.kaggle.com/priteshshrivastava/ieee-pipeline-3-stacking-with-meta-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is based on Inversion's simple xgb kernel : https://www.kaggle.com/inversion/ieee-simple-xgboost/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ieee-fraud-detection/train_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_transaction.csv\n",
      "/kaggle/input/ieee-fraud-detection/sample_submission.csv\n",
      "/kaggle/input/ieee-fraud-detection/train_transaction.csv\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/__output__.json\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/test_df.pkl\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/val_X.pkl\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/__notebook__.ipynb\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/train_y.csv\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/__results__.html\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/custom.css\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/val_y.csv\n",
      "/kaggle/input/ieee-pipeline-1-create-validation-set/train_X.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.read_pickle(\"/kaggle/input/ieee-pipeline-1-create-validation-set/train_X.pkl\")\n",
    "train_y = pd.read_csv(\"/kaggle/input/ieee-pipeline-1-create-validation-set/train_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = pd.read_pickle(\"/kaggle/input/ieee-pipeline-1-create-validation-set/val_X.pkl\")\n",
    "val_y = pd.read_csv(\"/kaggle/input/ieee-pipeline-1-create-validation-set/val_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3663549</th>\n",
       "      <td>18403224</td>\n",
       "      <td>31.950001</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111</td>\n",
       "      <td>150</td>\n",
       "      <td>visa</td>\n",
       "      <td>226</td>\n",
       "      <td>debit</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663550</th>\n",
       "      <td>18403263</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111</td>\n",
       "      <td>150</td>\n",
       "      <td>visa</td>\n",
       "      <td>226</td>\n",
       "      <td>debit</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663551</th>\n",
       "      <td>18403310</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574</td>\n",
       "      <td>150</td>\n",
       "      <td>visa</td>\n",
       "      <td>226</td>\n",
       "      <td>debit</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663552</th>\n",
       "      <td>18403310</td>\n",
       "      <td>284.950012</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360</td>\n",
       "      <td>150</td>\n",
       "      <td>visa</td>\n",
       "      <td>166</td>\n",
       "      <td>debit</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663553</th>\n",
       "      <td>18403317</td>\n",
       "      <td>67.949997</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452</td>\n",
       "      <td>150</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117</td>\n",
       "      <td>debit</td>\n",
       "      <td>264</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TransactionDT  TransactionAmt ProductCD  card1  card2  card3  \\\n",
       "TransactionID                                                                 \n",
       "3663549             18403224       31.950001         W  10409    111    150   \n",
       "3663550             18403263       49.000000         W   4272    111    150   \n",
       "3663551             18403310      171.000000         W   4476    574    150   \n",
       "3663552             18403310      284.950012         W  10989    360    150   \n",
       "3663553             18403317       67.949997         W  18018    452    150   \n",
       "\n",
       "                    card4  card5  card6  addr1  ...  id_31  id_32  id_33  \\\n",
       "TransactionID                                   ...                        \n",
       "3663549              visa    226  debit    170  ...    NaN      7    NaN   \n",
       "3663550              visa    226  debit    299  ...    NaN      7    NaN   \n",
       "3663551              visa    226  debit    472  ...    NaN      7    NaN   \n",
       "3663552              visa    166  debit    205  ...    NaN      7    NaN   \n",
       "3663553        mastercard    117  debit    264  ...    NaN      7    NaN   \n",
       "\n",
       "              id_34 id_35  id_36  id_37  id_38  DeviceType  DeviceInfo  \n",
       "TransactionID                                                           \n",
       "3663549         NaN   NaN    NaN    NaN    NaN         NaN         NaN  \n",
       "3663550         NaN   NaN    NaN    NaN    NaN         NaN         NaN  \n",
       "3663551         NaN   NaN    NaN    NaN    NaN         NaN         NaN  \n",
       "3663552         NaN   NaN    NaN    NaN    NaN         NaN         NaN  \n",
       "3663553         NaN   NaN    NaN    NaN    NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 432 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(\"/kaggle/input/ieee-pipeline-1-create-validation-set/test_df.pkl\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values & categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.fillna(-999)\n",
    "val_X = val_X.fillna(-999)\n",
    "test_df = test_df.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for f in train_X.columns:\n",
    "    if train_X[f].dtype=='object' or val_X[f].dtype=='object' or test_df[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_X[f].values) + list(val_X[f].values) + list(test_df[f].values))\n",
    "        train_X[f] = lbl.transform(list(train_X[f].values))\n",
    "        val_X[f] = lbl.transform(list(val_X[f].values))\n",
    "        test_df[f] = lbl.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function to calculate the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(x,y): \n",
    "    return roc_auc_score(x,y)\n",
    "def print_score(m):\n",
    "    #res = [auc(m.predict_proba(train_X)[:,1], train_y), auc(m.predict_proba(val_X)[:,1], val_y)]  ## continuous not supported\n",
    "    res = [auc(m.predict(train_X), train_y), auc(m.predict(val_X), val_y)]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC = xgb.XGBClassifier(n_estimators=500,\n",
    "                        n_jobs=4,\n",
    "                        max_depth=9,\n",
    "                        learning_rate=0.05,\n",
    "                        subsample=0.9,\n",
    "                        colsample_bytree=0.9,\n",
    "                        missing=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=1, missing=-999, n_estimators=500, n_jobs=4,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=0.9, verbosity=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelC.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9958716069016625, 0.9586296308469887]\n"
     ]
    }
   ],
   "source": [
    "print_score(modelC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on validation AND test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsC = pd.Series(modelC.predict_proba(val_X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predsC = pd.Series(modelC.predict_proba(test_df)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing val & test pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsC.to_csv(\"predsC.csv\", index = False, header = True)\n",
    "test_predsC.to_csv(\"test_predsC.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a submission file for the single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/ieee-fraud-detection/sample_submission.csv\")\n",
    "sample_submission['isFraud'] = modelC.predict_proba(test_df)[:,1]\n",
    "sample_submission.to_csv('simple_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
